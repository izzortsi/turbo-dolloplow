{"cells":[{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["%matplotlib widget\n","import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from pandas.core.frame import DataFrame\n","import seaborn as sns\n","import tensorflow as tf\n","\n","from grabber import *\n","from binance.client import Client\n","\n","mpl.rcParams['figure.figsize'] = (10, 10)\n","mpl.rcParams['axes.grid'] = False\n"]},{"cell_type":"markdown","metadata":{},"source":["Escolha do symbol, tamanho das candles, e período do mercado."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","symbol=\"ETHUSDT\"\n","tframe = \"1m\"\n","startTime = \"18 Nov, 2021\"\n","endTime = None\n"]},{"cell_type":"markdown","metadata":{},"source":["Inicializar o cliente e pegar as candles."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/istrozzi/.clones/turbo-dolloplow/grabber.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dohlcv[0] = pd.to_datetime(dohlcv[0], unit=\"ms\")\n"]}],"source":["client=Client()\n","grab = Grabber(client)\n","grab.get_historical_ohlcv(symbol=symbol, tframe=tframe, startTime=startTime)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-11-18 00:00:00</th>\n","      <td>4288.07</td>\n","      <td>4291.74</td>\n","      <td>4284.80</td>\n","      <td>4288.00</td>\n","      <td>486.9333</td>\n","    </tr>\n","    <tr>\n","      <th>2021-11-18 00:01:00</th>\n","      <td>4288.00</td>\n","      <td>4298.79</td>\n","      <td>4283.59</td>\n","      <td>4283.59</td>\n","      <td>551.3734</td>\n","    </tr>\n","    <tr>\n","      <th>2021-11-18 00:02:00</th>\n","      <td>4283.59</td>\n","      <td>4283.59</td>\n","      <td>4273.39</td>\n","      <td>4274.92</td>\n","      <td>420.3734</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open     high      low    close    volume\n","date                                                             \n","2021-11-18 00:00:00  4288.07  4291.74  4284.80  4288.00  486.9333\n","2021-11-18 00:01:00  4288.00  4298.79  4283.59  4283.59  551.3734\n","2021-11-18 00:02:00  4283.59  4283.59  4273.39  4274.92  420.3734"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["#criando uma nova variável pros dados e checkando os mesmos\n","df = grab.ohlcvs[symbol]\n","df.head(3)"]},{"cell_type":"markdown","metadata":{},"source":["# 1 Determinação de janelas\n","$\\mathrm{ma_{w_1}}$ é a moving average com janela $w_1$; $\\mathrm{ema_{w_1}}$ é a exponential moving average com janela $w_1$. Em geral o desvio-padrão pra uma média de janela $w_1$ vai ser escrito como $\\mathrm{std}_{w_1}$, contanto que não haja mais de uma média com essa janela; ou, então, será escrito como $\\mathrm{std}(M_1)$, se dada alguma média $M_1$. A média aritmética simples de um conjunto, lista ou vetor será simplesmente $\\mathrm{mean}$.\n","Serão necessárias pelo menos duas médias dos preços, ambas exponenciais, uma de cauda mais curta e outra de cauda mais longa. Seja $C$ o vetor de preços. \n","A média de cauda mais curta, $M_1 = \\mathrm{ema_{w_1}}(C)$, tem que satisfazer a propriedade:\n","$$\\frac{\\mathrm{mean}(\\mathrm{std}(M_1))}{\\mathrm{mean}(M_1)} > \\mathrm{fee} + \\varepsilon $$\n","\n","sendo $\\mathrm{fee}$ o custo percentual total das taxas de transação (0.08% na binance) e $\\varepsilon$ um parâmetro do programa. A idéia é que o $\\varepsilon$ determine uma \"margem de segurança\", enquanto o lado esquerdo da equação mede o quanto, percentualmente, o desvio-padrão médio corresponde ao preço médio. Ou seja, tendo uma janela $w_1$ seguramente (o que é determinado por $\\varepsilon$) maior que o que se paga de taxa nas transações, temos uma primeira garantia, a de que, aproveitada suficientemente bem a volatilidade, ie, aberto um long suficientemente perto do \"bottom\" médio, a"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","w1 = 5\n","w2 = 12\n","\n","closesMean1 = df.close.ewm(span=w1).mean()\n","closesStd1 = df.close.ewm(span=w1).std()\n","\n","\n","\n","pmean2 = df.close.ewm(span=w2).mean()\n","pstd2 = df.close.ewm(span=w2).std()\n","\n","\n","\n","# hmean1 = df.high.ewm(span=3).mean()\n","# lmean1 = df.low.ewm(span=3).mean()\n","hmean1 = df.high\n","lmean1 = df.low\n","# pstd2 = df.close.ewm(span=w2).std()\n","\n","def showcurves(c1):\n","\n","  fig, ax = plt.subplots()\n","  ax.set_title('click on points')\n","\n","  line, = ax.plot(np.random.rand(100), 'o',\n","                  picker=True, pickradius=5)  # 5 points tolerance\n","  plt.show()\n","\n","  return fig, ax, line\n","\n","\n","\n","fig = plt.figure(figsize=(12, 8))\n","ax = plt.axes()\n","ax.plot(df.close, c=\"k\", label=f\"closes\", linewidth=2)\n","ax.plot(pmean1+1.17*pstd1, \"k--\", label=f\"closes {w1} ema\", linewidth=1.5)\n","ax.plot(pmean1-1.17*pstd1, \"k--\", label=f\"closes {w1} ema\", linewidth=1.5)\n","ax.plot(pmean1, \"b-\", linewidth=2, label=f\"closes {w1} ema\", alpha=0.8)\n","ax.plot(pmean2, \"y-\", linewidth=2, label=f\"closes {w2} ema\", alpha=0.8)\n","ax.plot(pmean2+0.8*pstd2, \"g--\", alpha=0.8)\n","ax.plot(pmean2-0.8*pstd2, \"r--\", alpha=0.8)\n","# including upper limits\n","\n","yerrs = [df.high-df.close, df.low-df.close]\n","\n","mom1 = df.close - df.close.shift(-1)\n","\n","colors = [\"green\" if c > 0 else \"red\" for c in mom1]\n","# reds = (mom1 <= 0).map(lambda _: \"red\" if True else \"green\")\n","\n","ax.vlines(df.index, ymin=df.close+yerrs[1], ymax=yerrs[0]+df.close, color=colors, alpha=1)\n","# ax.axhspan(yerrs[0], yerrs[1], facecolor='0.5')\n","# colors = (sums.loc[sums <= 0].index).map(lambda: \"red\" if True)\n","# if \n","# ax.errorbar(df.index, df.close, yerr=yerrs,\n","#              linestyle=\"-\", linewidth=1.5, ecolor=\"m\")\n","# ax.errorbar(df.index, df.close, yerr=df.close-df.low,\n","#              linestyle=\"-\", linewidth=2.0, color=\"red\")\n","# ax.errorbar(df.index, pmean1,  uplims=df.high-df.close, lolims=df.close - df.low,\n","#              label='subsets of uplims and lolims')\n","# # including lower limits\n","# ax.errorbar(x, y + 1.0, xerr=xerr, yerr=yerr, lolims=lolims,\n","#             linestyle=ls);\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.index"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","pmean1, pstd1, pmean2, pstd2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","std_mean1 = pstd1/pmean1\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["std_mean1.mean()*100 # escolher w1 w2 de forma q isso seja maior que a fee de 0.08%"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["std_mean2 = pstd2/pmean2\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["std_mean2.mean()*100\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.close"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","pdifhl = (df.high.shift(-w1) -df.low)/df.high.shift(-w1)*100\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pdif = (df.close.shift(-w1) - df.close)/df.close.shift(-w1)*100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["posdiffs = pdif >= 0\n","negdiffs = pdif < 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["diffs = negdiffs*0 + posdiffs*1 #esse é o alvo: dizer se em w1 a diff é positiva ou negativa\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["diffs.head(100).plot()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#agora tenho que colocar as features mais adequadas pra esse alvo"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def feature_engineer(df, w: int, p: int):\n","  df.rolling.stdev(append=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.ta.cci(append=True)\n","df.ta.cg(append=True)\n","df.ta.roc(append=True)\n","df.ta.cci(append=True)\n","df.ta.pvo(append=True)\n","df.ta.stochrsi(append=True)\n","\n","df.ta.entropy(append=True)\n","df.ta.kurtosis(append=True)\n","df.ta.median(append=True)\n","df.ta.skew(append=True)\n","df.ta.stdev(append=True)\n","df.ta.dpo(lookahead=False, append=True)\n","# kldf.ta.increasing(append=True)\n","# kldf.ta.decreasing(append=True)\n","df.ta.aberration(append=True)\n","df.ta.natr(append=True)\n","df.ta.massi(append=True)\n","df.ta.pdist(append=True)\n","df.ta.rvi(append=True)\n","df = df.dropna()\n","df.index\n","date_time = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n","\n","\n","# plot_cols = [\"close\", \"PDIST\"]\n","# plot_features = df[plot_cols]\n","# plot_features.index = date_time\n","# _ = plot_features.plot(subplots=True)\n","\n","# plot_features = df[plot_cols][:480]\n","# plot_features.index = date_time[:480]\n","# _ = plot_features.plot(subplots=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["column_indices = {name: i for i, name in enumerate(df.columns)}\n","\n","n = len(df)\n","train_df = df[0:int(n*0.7)]\n","val_df = df[int(n*0.7):int(n*0.9)]\n","test_df = df[int(n*0.9):]\n","\n","num_features = df.shape[1]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_mean = train_df.mean()\n","train_std = train_df.std()\n","\n","train_df = (train_df - train_mean) / train_std\n","val_df = (val_df - train_mean) / train_std\n","test_df = (test_df - train_mean) / train_std\n"]},{"cell_type":"markdown","metadata":{},"source":[" Now peek at the distribution of the features. Some features do have long tails, but there are no obvious errors like the `-9999` wind velocity value."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_std = (df - train_mean) / train_std\n","df_std = df_std.melt(var_name='Column', value_name='Normalized')\n","plt.figure(figsize=(12, 6))\n","ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n","_ = ax.set_xticklabels(df.keys(), rotation=90)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class WindowGenerator():\n","  def __init__(self, input_width, label_width, shift,\n","               train_df=train_df, val_df=val_df, test_df=test_df,\n","               label_columns=None):\n","    # Store the raw data.\n","    self.train_df = train_df\n","    self.val_df = val_df\n","    self.test_df = test_df\n","\n","    # Work out the label column indices.\n","    self.label_columns = label_columns\n","    if label_columns is not None:\n","      self.label_columns_indices = {name: i for i, name in\n","                                    enumerate(label_columns)}\n","    self.column_indices = {name: i for i, name in\n","                           enumerate(train_df.columns)}\n","\n","    # Work out the window parameters.\n","    self.input_width = input_width\n","    self.label_width = label_width\n","    self.shift = shift\n","\n","    self.total_window_size = input_width + shift\n","\n","    self.input_slice = slice(0, input_width)\n","    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n","\n","    self.label_start = self.total_window_size - self.label_width\n","    self.labels_slice = slice(self.label_start, None)\n","    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n","\n","  def __repr__(self):\n","    return '\\n'.join([\n","        f'Total window size: {self.total_window_size}',\n","        f'Input indices: {self.input_indices}',\n","        f'Label indices: {self.label_indices}',\n","        f'Label column name(s): {self.label_columns}'])\n","\n","\n","def split_window(self, features):\n","  inputs = features[:, self.input_slice, :]\n","  labels = features[:, self.labels_slice, :]\n","  if self.label_columns is not None:\n","    labels = tf.stack(\n","        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n","        axis=-1)\n","\n","  # Slicing doesn't preserve static shape information, so set the shapes\n","  # manually. This way the `tf.data.Datasets` are easier to inspect.\n","  inputs.set_shape([None, self.input_width, None])\n","  labels.set_shape([None, self.label_width, None])\n","\n","  return inputs, labels\n","\n","WindowGenerator.split_window = split_window\n","\n","\n","def plot(self, model=None, plot_col='close', max_subplots=3):\n","  inputs, labels = self.example\n","  plt.figure(figsize=(12, 8))\n","  plot_col_index = self.column_indices[plot_col]\n","  max_n = min(max_subplots, len(inputs))\n","  for n in range(max_n):\n","    plt.subplot(max_n, 1, n+1)\n","    plt.ylabel(f'{plot_col} [normed]')\n","    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n","             label='Inputs', marker='.', zorder=-10)\n","\n","    if self.label_columns:\n","      label_col_index = self.label_columns_indices.get(plot_col, None)\n","    else:\n","      label_col_index = plot_col_index\n","\n","    if label_col_index is None:\n","      continue\n","\n","    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n","                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n","    if model is not None:\n","      predictions = model(inputs)\n","      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n","                  marker='X', edgecolors='k', label='Predictions',\n","                  c='#ff7f0e', s=64)\n","\n","    if n == 0:\n","      plt.legend()\n","\n","  plt.xlabel('Time [h]')\n","\n","WindowGenerator.plot = plot\n","\n","\n","def make_dataset(self, data):\n","  data = np.array(data, dtype=np.float32)\n","  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n","      data=data,\n","      targets=None,\n","      sequence_length=self.total_window_size,\n","      sequence_stride=1,\n","      shuffle=True,\n","      batch_size=32,)\n","\n","  ds = ds.map(self.split_window)\n","\n","  return ds\n","\n","WindowGenerator.make_dataset = make_dataset\n","\n","\n","# The `WindowGenerator` object holds training, validation and test data. Add properties for accessing them as `tf.data.Datasets` using the above `make_dataset` method. Also add a standard example batch for easy access and plotting:\n","\n","@property\n","def train(self):\n","  return self.make_dataset(self.train_df)\n","\n","@property\n","def val(self):\n","  return self.make_dataset(self.val_df)\n","\n","@property\n","def test(self):\n","  return self.make_dataset(self.test_df)\n","\n","@property\n","def example(self):\n","  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n","  result = getattr(self, '_example', None)\n","  if result is None:\n","    # No example batch was found, so get one from the `.train` dataset\n","    result = next(iter(self.train))\n","    # And cache it for next time\n","    self._example = result\n","  return result\n","\n","WindowGenerator.train = train\n","WindowGenerator.val = val\n","WindowGenerator.test = test\n","WindowGenerator.example = example\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","MAX_EPOCHS = 20\n","\n","def compile_and_fit(model, window, patience=2):\n","  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                    patience=patience,\n","                                                    mode='min')\n","\n","  model.compile(loss=tf.losses.MeanSquaredError(),\n","                optimizer=tf.optimizers.Adam(),\n","                metrics=[tf.metrics.MeanAbsoluteError()])\n","\n","  history = model.fit(window.train, epochs=MAX_EPOCHS,\n","                      validation_data=window.val,\n","                      callbacks=[early_stopping])\n","  return history"]},{"cell_type":"markdown","metadata":{},"source":[" Now the `WindowGenerator` object gives you access to the `tf.data.Dataset` objects, so you can easily iterate over the data.\n","\n"," The `Dataset.element_spec` property tells you the structure, `dtypes` and shapes of the dataset elements."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["w1 = WindowGenerator(input_width=24, label_width=1, shift=24,\n","                     label_columns=['close'])\n","\n","\n","\n","w2 = WindowGenerator(input_width=6, label_width=1, shift=1,\n","                     label_columns=['close'])\n","\n","\n","single_step_window = WindowGenerator(\n","    input_width=1, label_width=1, shift=1,\n","    label_columns=['close'])\n","single_step_window\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Baseline(tf.keras.Model):\n","  def __init__(self, label_index=None):\n","    super().__init__()\n","    self.label_index = label_index\n","\n","  def call(self, inputs):\n","    if self.label_index is None:\n","      return inputs\n","    result = inputs[:, :, self.label_index]\n","    return result[:, :, tf.newaxis]\n","\n","baseline = Baseline(label_index=column_indices['close'])\n","\n","baseline.compile(loss=tf.losses.MeanSquaredError(),\n","                 metrics=[tf.metrics.MeanAbsoluteError()])\n","\n","val_performance = {}\n","performance = {}\n","val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n","performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1,\n","    label_columns=['close'])\n","\n","wide_window\n","\n","\n","print('Input shape:', wide_window.example[0].shape)\n","print('Output shape:', baseline(wide_window.example[0]).shape)\n","\n","\n","wide_window.plot(baseline)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CONV_WIDTH = 6\n","conv_window = WindowGenerator(\n","    input_width=CONV_WIDTH,\n","    label_width=1,\n","    shift=1,\n","    label_columns=['close'])\n","\n","conv_window\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["conv_window.plot()\n","plt.title(\"Given 3h as input, predict 1h into the future.\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[" Note that the output is shorter than the input. To make training or plotting work, you need the labels, and prediction to have the same length. So build a `WindowGenerator` to produce wide windows with a few extra input time steps so the label and prediction lengths match:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LABEL_WIDTH = 24\n","INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n","wide_conv_window = WindowGenerator(\n","    input_width=INPUT_WIDTH,\n","    label_width=LABEL_WIDTH,\n","    shift=1,\n","    label_columns=['close'])\n","\n","wide_conv_window\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lstm_model = tf.keras.models.Sequential([\n","    # Shape [batch, time, features] => [batch, time, lstm_units]\n","    tf.keras.layers.LSTM(32, return_sequences=True),\n","    # Shape => [batch, time, features]\n","    tf.keras.layers.Dense(units=1)\n","])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Input shape:', wide_window.example[0].shape)\n","print('Output shape:', lstm_model(wide_window.example[0]).shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history = compile_and_fit(lstm_model, wide_window)\n","\n","IPython.display.clear_output()\n","val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n","performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wide_window.plot(lstm_model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_x"]},{"cell_type":"markdown","metadata":{},"source":[" ### Performance"]},{"cell_type":"markdown","metadata":{},"source":[" With this dataset typically each of the models does slightly better than the one before it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = np.arange(len(performance))\n","width = 0.3\n","metric_name = 'mean_absolute_error'\n","metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n","val_mae = [v[metric_index] for v in val_performance.values()]\n","test_mae = [v[metric_index] for v in performance.values()]\n","\n","plt.ylabel('mean_absolute_error [T (degC), normalized]')\n","plt.bar(x - 0.17, val_mae, width, label='Validation')\n","plt.bar(x + 0.17, test_mae, width, label='Test')\n","plt.xticks(ticks=x, labels=performance.keys(),\n","           rotation=45)\n","_ = plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name, value in performance.items():\n","  print(f'{name:12s}: {value[1]:0.4f}')\n"]},{"cell_type":"markdown","metadata":{},"source":[" ### Multi-output models\n","\n"," The models so far all predicted a single output feature, `T (degC)`, for a single time step.\n","\n"," All of these models can be converted to predict multiple features just by changing the number of units in the output layer and adjusting the training windows to include all features in the `labels`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["single_step_window = WindowGenerator(\n","    # `WindowGenerator` returns all features as labels if you \n","    # don't set the `label_columns` argument.\n","    input_width=1, label_width=1, shift=1)\n","\n","wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1)\n","\n","for example_inputs, example_labels in wide_window.train.take(1):\n","  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n","  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n"]},{"cell_type":"markdown","metadata":{},"source":[" Note above that the `features` axis of the labels now has the same depth as the inputs, instead of 1."]},{"cell_type":"markdown","metadata":{},"source":[" #### Baseline\n","\n"," The same baseline model can be used here, but this time repeating all features instead of selecting a specific `label_index`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["baseline = Baseline()\n","baseline.compile(loss=tf.losses.MeanSquaredError(),\n","                 metrics=[tf.metrics.MeanAbsoluteError()])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["val_performance = {}\n","performance = {}\n","val_performance['Baseline'] = baseline.evaluate(wide_window.val)\n","performance['Baseline'] = baseline.evaluate(wide_window.test, verbose=0)\n"]},{"cell_type":"markdown","metadata":{},"source":[" #### Dense"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dense = tf.keras.Sequential([\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=64, activation='relu'),\n","    tf.keras.layers.Dense(units=num_features)\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history = compile_and_fit(dense, single_step_window)\n","\n","IPython.display.clear_output()\n","val_performance['Dense'] = dense.evaluate(single_step_window.val)\n","performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)\n"]},{"cell_type":"markdown","metadata":{},"source":[" #### RNN\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wide_window = WindowGenerator(\n","    input_width=24, label_width=24, shift=1)\n","\n","lstm_model = tf.keras.models.Sequential([\n","    # Shape [batch, time, features] => [batch, time, lstm_units]\n","    tf.keras.layers.LSTM(32, return_sequences=True),\n","    # Shape => [batch, time, features]\n","    tf.keras.layers.Dense(units=num_features)\n","])\n","\n","history = compile_and_fit(lstm_model, wide_window)\n","\n","IPython.display.clear_output()\n","val_performance['LSTM'] = lstm_model.evaluate( wide_window.val)\n","performance['LSTM'] = lstm_model.evaluate( wide_window.test, verbose=0)\n","\n","print()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
